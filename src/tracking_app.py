from ultralytics import YOLO
import cv2
import os, datetime
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from collections import defaultdict # è¿½åŠ : ãƒ‡ãƒ¼ã‚¿ã®å±¥æ­´ä¿å­˜ç”¨

# --- è¨­å®šã‚¨ãƒªã‚¢ ---
SOURCE = "854100-hd_1920_1080_25fps.mp4" 
model_name = 'yolo11n.pt' 

# ç¿»è¨³è¾æ›¸
CLASS_NAMES_JA = {
    "person": "äºº", "bicycle": "è‡ªè»¢è»Š", "car": "è»Š", "motorcycle": "ãƒã‚¤ã‚¯",
    "bus": "ãƒã‚¹", "truck": "ãƒˆãƒ©ãƒƒã‚¯", "cat": "çŒ«", "dog": "çŠ¬", "chair": "æ¤…å­"
    # ... å¿…è¦ã«å¿œã˜ã¦è¿½åŠ  ...
}
# ------------------

# --- è¿½åŠ æ©Ÿèƒ½è¨­å®š: è»Œè·¡ ---
track_history = defaultdict(lambda: []) # IDã”ã¨ã®åº§æ¨™å±¥æ­´ã‚’ä¿å­˜
MAX_TRAIL_LENGTH = 30 # éå»ä½•ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®è»Œè·¡ã‚’æ®‹ã™ã‹ï¼ˆé•·ãã™ã‚‹ã¨ç·šãŒé•·ããªã‚‹ï¼‰

def put_japanese_text(img, text, position, font, text_color=(255, 255, 255), active_fill=True):
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    bbox = draw.textbbox(position, text, font=font)
    if active_fill:
        draw.rectangle(bbox, fill=(0, 0, 0))
    draw.text(position, text, font=font, fill=text_color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
font_path = "C:\\Windows\\Fonts\\msgothic.ttc"
try:
    font = ImageFont.truetype(font_path, 32)
    font_small = ImageFont.truetype(font_path, 20)
except OSError:
    font = ImageFont.load_default()
    font_small = ImageFont.load_default()

print(f"Loading {model_name}...")
model = YOLO(model_name)

input_source = SOURCE
if isinstance(SOURCE, str) and SOURCE.isdigit():
    input_source = int(SOURCE)

cap = cv2.VideoCapture(input_source)
if not cap.isOpened():
    print(f"Error opening {input_source}")
    exit()

width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)
if fps == 0: fps = 30.0

output_filename = f"output_trails_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_filename, fourcc, fps, (width, height))

print("é–‹å§‹ã—ã¾ã™ã€‚'q'ã§çµ‚äº†ã€'s'ã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜")

# ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
RESULTS_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "results")
os.makedirs(RESULTS_DIR, exist_ok=True)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # è¿½è·¡å®Ÿè¡Œ
    results = model.track(frame, persist=True, tracker="bytetrack.yaml", verbose=False)
    annotated_frame = frame.copy()
    
    boxes = results[0].boxes
    person_count = 0
    
    if boxes is not None and boxes.id is not None:
        # IDã¨åº§æ¨™ã‚’ã¾ã¨ã‚ã¦å–å¾— (GPU->CPUå¤‰æ›å«ã‚€)
        track_ids = boxes.id.int().cpu().tolist()
        boxes_xyxy = boxes.xyxy.cpu().tolist()
        classes = boxes.cls.int().cpu().tolist()

        # ZIPã§ã¾ã¨ã‚ã¦ãƒ«ãƒ¼ãƒ—å‡¦ç†
        for box_id, box_xyxy, cls_id in zip(track_ids, boxes_xyxy, classes):
            
            english_name = model.names[cls_id]
            label_text = CLASS_NAMES_JA.get(english_name, english_name)
            
            # è‰²è¨­å®š & ã‚«ã‚¦ãƒ³ãƒˆ
            if english_name == 'person':
                person_count += 1
                color = (0, 0, 255)
            else:
                color = (0, 255, 0)
            
            x1, y1, x2, y2 = map(int, box_xyxy)
            
            # ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—
            center_x = int((x1 + x2) / 2)
            center_y = int((y1 + y2) / 2) # è¶³å…ƒã«ã—ãŸã„å ´åˆã¯ int(y2) ã«ã™ã‚‹

            # --- â˜…ã“ã“ãŒè¿½åŠ æ©Ÿèƒ½: è»Œè·¡ã®å‡¦ç† ---
            track = track_history[box_id]
            track.append((center_x, center_y))
            if len(track) > MAX_TRAIL_LENGTH:
                track.pop(0) # å¤ã„å±¥æ­´ã‚’å‰Šé™¤

            # è»Œè·¡ã‚’æç”» (è¤‡æ•°ã®ç‚¹ã‚’ç·šã§çµã¶)
            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))
            cv2.polylines(annotated_frame, [points], isClosed=False, color=color, thickness=2)
            # ----------------------------------

            label_text += f" {box_id}"
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
            annotated_frame = put_japanese_text(annotated_frame, label_text, (x1, y1 - 30), font_small, (255, 255, 255))

    count_text = f"æ¤œå‡ºäººæ•°: {person_count}äºº"
    annotated_frame = put_japanese_text(annotated_frame, count_text, (10, 10), font, (0, 255, 255), active_fill=True)

    out.write(annotated_frame)
    cv2.imshow("YOLO11 Japanese Tracking & Trails", annotated_frame)

    key = cv2.waitKey(1) & 0xFF
    if key == ord('s') or key == ord('S'):
        fname = datetime.datetime.now().strftime('%Y%m%d_%H%M%S.png')
        save_path = os.path.join(RESULTS_DIR, fname)
        cv2.imwrite(save_path, annotated_frame)
        print(f"ğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜: {save_path}", flush=True)
    elif key == ord('q'):
        break

cap.release()
out.release()
cv2.destroyAllWindows()